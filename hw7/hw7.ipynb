{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "pIFEbKPj7HhF",
    "outputId": "b15522e4-9042-48c3-d670-6def7d96ec7f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.32.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zYtz9-sJ4kGt"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import GradScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    VisionEncoderDecoderModel,\n",
    "    ViTImageProcessor,\n",
    "    AutoTokenizer,\n",
    "    default_data_collator,\n",
    "    get_cosine_schedule_with_warmup,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1plZKFS4mY3",
    "outputId": "7ac9d57d-fd7a-419d-9755-f9693e8b23dc"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "model_name = \"nlpconnect/vit-gpt2-image-captioning\" \n",
    "out = \"vitgpt2_flickr8k_finetuned\"\n",
    "ds_name = \"Naveengo/flickr8k\"     \n",
    "split = \"train\"\n",
    "cnt = 2000                   \n",
    "batch_size = 32                      \n",
    "n_epochs = 1\n",
    "learning_rate = 2e-5                    \n",
    "m_targer_len = 32\n",
    "dev = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "Path(out).mkdir(parents=True, exist_ok=True)\n",
    "print(f\"dev: {dev}\")\n",
    "\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "pfO8OgAI4tZV",
    "outputId": "9ccec0b7-0fa8-4a79-ec3e-a4a19ab8633e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded 2000 examples\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(ds_name, split=split)\n",
    "if cnt and len(dataset) > cnt:\n",
    "    dataset = dataset.shuffle(seed=42).select(range(cnt))\n",
    "print(\"Loaded\", len(dataset), \"examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "b-QM3WuX4w7u"
   },
   "outputs": [],
   "source": [
    "model = VisionEncoderDecoderModel.from_pretrained(model_name).to(dev)\n",
    "feature_extractor = ViTImageProcessor.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "for p in model.get_encoder().parameters():\n",
    "    p.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fzZHLPeZ41YI"
   },
   "outputs": [],
   "source": [
    "def transform(example):\n",
    "    pixel = feature_extractor(example[\"image\"], return_tensors=\"pt\").pixel_values[0]\n",
    "    ids = tokenizer(\n",
    "        example[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=m_targer_len,\n",
    "        return_tensors=\"pt\",\n",
    "    ).input_ids[0]\n",
    "    ids[ids == tokenizer.pad_token_id] = -100\n",
    "    return {\"pixel_values\": pixel, \"labels\": ids}\n",
    "\n",
    "train_dataset = dataset.map(transform, remove_columns=dataset.column_names)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=default_data_collator,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HHGZU-mG43iN"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), learning_rate=learning_rate)\n",
    "total_steps = len(train_loader) * n_epochs\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(0.1 * total_steps),\n",
    "    num_training_steps=total_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nuI_2zbZ47BY",
    "outputId": "3b611e36-ce5f-451c-e8de-d4ca909321f7"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-8-2634025278>:1: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=DEVICE == \"cuda\")\n",
      "Epoch 1/1:   0%|          | 0/63 [00:00<?, ?it/s]We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "You may ignore this warning if your `pad_token_id` (50256) is identical to the `bos_token_id` (50256), `eos_token_id` (50256), or the `sep_token_id` (None), and your input is not padded.\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
      "Epoch 1/1: 100%|██████████| 63/63 [48:15<00:00, 45.96s/it, loss=5.5471]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1 mean loss: 6.2497\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = GradScaler(enabled=dev == \"cuda\")\n",
    "model.train()\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    progress = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{n_epochs}\")\n",
    "    for batch in progress:\n",
    "        batch = {k: v.to(dev, non_blocking=True) for k, v in batch.items()}\n",
    "        with torch.autocast(\"cuda\", dtype=torch.float16, enabled=dev == \"cuda\"):\n",
    "            loss = model(**batch).loss\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        scheduler.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        progress.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} mean loss: {epoch_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "0M8qdlqz4YUx",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f2dcaff2-58d5-4649-9135-fb7e64b9473a"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('vitgpt2_flickr8k_finetuned/tokenizer_config.json',\n",
       " 'vitgpt2_flickr8k_finetuned/special_tokens_map.json',\n",
       " 'vitgpt2_flickr8k_finetuned/vocab.json',\n",
       " 'vitgpt2_flickr8k_finetuned/merges.txt',\n",
       " 'vitgpt2_flickr8k_finetuned/added_tokens.json',\n",
       " 'vitgpt2_flickr8k_finetuned/tokenizer.json')"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "model.save_pretrained(out)\n",
    "feature_extractor.save_pretrained(out)\n",
    "tokenizer.save_pretrained(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "pawpk1eyGDJz",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c4ba7a4f-674f-4ee1-e466-b577f0ab4752"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.53.0. You should pass an instance of `Cache` instead, e.g. `past_key_values=DynamicCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a\n",
      "a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a\n",
      "dogs and dogs in grassy area with dog in grassy area \n",
      " girl and girl on a a a a a a a a a a a a a a a a a a a a a a a a a a a\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sample = dataset.shuffle(seed=123).select(range(4))\n",
    "    pixels = feature_extractor(sample[\"image\"], return_tensors=\"pt\").pixel_values.to(dev)\n",
    "    with torch.autocast(\"cuda\", dtype=torch.float16, enabled=dev == \"cuda\"):\n",
    "        gen_ids = model.generate(pixels, max_length=m_targer_len)\n",
    "    captions = tokenizer.batch_decode(gen_ids, skip_special_tokens=True)\n",
    "\n",
    "for cap in captions:\n",
    "    print(cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Выводы:\n",
    "\n",
    "Эта штука на ресурсах коллаба вообще не училась(\n",
    "\n",
    "По итогу я сначала пытался уменьшить размер датасета (4000 -> 2000)\n",
    "\n",
    "Не сказать что это сильно помогло, и сам ноутбук падал после первой же эпохи, как следствия я попробовал оставить всего одну эпоху - результаты удручающие\n",
    "\n",
    "Оставлю как есть, а то тут уже сроки проверки почти подошли, пусть лежит чтоб труды зря не проходили)"
   ],
   "metadata": {
    "id": "f2_YFwXcF7Lc"
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
