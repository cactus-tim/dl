{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install together"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "q5bLUv5qOWVX",
        "outputId": "d58f7a87-5551-44f7-f1e6-6714fc0a092d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting together\n",
            "  Downloading together-1.5.13-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in /usr/local/lib/python3.11/dist-packages (from together) (3.11.15)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from together) (8.2.1)\n",
            "Collecting eval-type-backport<0.3.0,>=0.1.3 (from together)\n",
            "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in /usr/local/lib/python3.11/dist-packages (from together) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from together) (2.0.2)\n",
            "Requirement already satisfied: pillow<12.0.0,>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from together) (11.2.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.6.3 in /usr/local/lib/python3.11/dist-packages (from together) (2.11.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from together) (2.32.3)\n",
            "Requirement already satisfied: rich<15.0.0,>=13.8.1 in /usr/local/lib/python3.11/dist-packages (from together) (13.9.4)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from together) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in /usr/local/lib/python3.11/dist-packages (from together) (4.67.1)\n",
            "Collecting typer<0.16,>=0.9 (from together)\n",
            "  Downloading typer-0.15.4-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.20.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (4.14.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (2025.4.26)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<15.0.0,>=13.8.1->together) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<15.0.0,>=13.8.1->together) (2.19.1)\n",
            "Collecting click<9.0.0,>=8.1.7 (from together)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.16,>=0.9->together) (1.5.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=13.8.1->together) (0.1.2)\n",
            "Downloading together-1.5.13-py3-none-any.whl (90 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.7/90.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
            "Downloading typer-0.15.4-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: eval-type-backport, click, typer, together\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.2.1\n",
            "    Uninstalling click-8.2.1:\n",
            "      Successfully uninstalled click-8.2.1\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.16.0\n",
            "    Uninstalling typer-0.16.0:\n",
            "      Successfully uninstalled typer-0.16.0\n",
            "Successfully installed click-8.1.8 eval-type-backport-0.2.2 together-1.5.13 typer-0.15.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "import re\n",
        "from pathlib import Path\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from itertools import product\n",
        "from typing import Literal\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "from tqdm import tqdm\n",
        "from together import Together"
      ],
      "metadata": {
        "id": "QS7UBT5GMwhX"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_labels(m: int) -> str:\n",
        "  if m == 1:\n",
        "    return \"world\"\n",
        "  elif m == 2:\n",
        "    return \"sports\"\n",
        "  elif m ==3:\n",
        "    return \"business\"\n",
        "  elif m == 4:\n",
        "    return \"sci/tech\""
      ],
      "metadata": {
        "id": "d4qGYdhkO87h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/test.csv\"\n",
        "df = pd.read_csv(url, header=None, names=[\"label\",\"title\",\"description\"])\n",
        "\n",
        "df[\"text\"] = df[\"title\"] + \". \" + df[\"description\"]\n",
        "df = df.sample(n=500, random_state=42).reset_index(drop=True)\n",
        "\n",
        "df['label'] = df['label'].map(encode_labels)\n",
        "\n",
        "texts = df[\"text\"].tolist()\n",
        "df = df[[\"label\", \"text\"]]"
      ],
      "metadata": {
        "id": "U6TzQehIM6Xy"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size = 200\n",
        "df_lim = (df.groupby(\"label\", sort=False).head(size).reset_index(drop=True))\n",
        "df_shuffled = df_lim.sample(frac=1, random_state=42).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "S0gbim03QSQ9"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NEWS_CATEGORIES = {\n",
        "    \"sports\":   \"Sports events, athletes, competitions\",\n",
        "    \"world\":    \"Global news, international affairs\",\n",
        "    \"sci/tech\": \"Science and technology, research, innovations\",\n",
        "    \"business\": \"Economy, markets, finance, companies\"\n",
        "}\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "You are a news categorization expert. Your task is to classify news texts into predefined categories.\n",
        "\n",
        "Available categories:\n",
        "{categories_list}\n",
        "\n",
        "Guidelines:\n",
        "- Be precise and consistent in your categorization\n",
        "- Consider the main theme and context of the text\n",
        "- If a text could fit multiple categories, choose the most dominant one\n",
        "- For soft classification, provide probability scores that sum to 1\n",
        "- For hard classification, select the single most appropriate category\n",
        "\"\"\".strip().format(\n",
        "    categories_list=\"\\n\".join(f\"- {cat}: {desc}\" for cat, desc in NEWS_CATEGORIES.items())\n",
        ")\n",
        "\n",
        "CLASSIFY_SOFT_PROMPT_TEMPLATE = \"\"\"\n",
        "Assign a probability score (0 < score < 1) to each category so they sum to 1.\n",
        "Wrap your response in <answer></answer> tags.\n",
        "\n",
        "# Expected format:\n",
        "<answer>\n",
        "{{\n",
        "    \"sports\":    <probability>,\n",
        "    \"world\":     <probability>,\n",
        "    \"sci/tech\":  <probability>,\n",
        "    \"business\":  <probability>\n",
        "}}\n",
        "</answer>\n",
        "\n",
        "News Text:\n",
        "{description}\n",
        "\n",
        "Provide only the JSON response without any additional text or explanations.\n",
        "\"\"\".strip()\n",
        "\n",
        "CLASSIFY_HARD_PROMPT_TEMPLATE = \"\"\"\n",
        "Select the most fitting category (among provided) for the given news text.\n",
        "Wrap your response in <answer></answer> tags.\n",
        "\n",
        "# Expected format:\n",
        "<answer>\n",
        "{{\n",
        "    \"Category\": \"<selected category>\"\n",
        "}}\n",
        "</answer>\n",
        "\n",
        "News Text:\n",
        "{description}\n",
        "\n",
        "Provide only the JSON response without any additional text or explanations.\n",
        "\"\"\".strip()"
      ],
      "metadata": {
        "id": "8lb7n7sIR6bG"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY = \"482616ebff87428b1a490e5a30e95bd730e7c52f38bba3d3e71c39039008aea0\"\n",
        "client = Together(api_key=API_KEY)\n",
        "batch_size = 16"
      ],
      "metadata": {
        "id": "6x1kpxGDR7T-"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_evaluation(model_name: str, mode: Literal[\"soft\", \"hard\"]) -> float:\n",
        "    template = (\n",
        "        CLASSIFY_SOFT_PROMPT_TEMPLATE if mode == \"soft\" else CLASSIFY_HARD_PROMPT_TEMPLATE\n",
        "    )\n",
        "    prompts = [template.format(description=row.text) for row in df_shuffled.itertuples()]\n",
        "    targets = list(df_shuffled.label)\n",
        "\n",
        "    def _worker(text_prompt: str) -> str:\n",
        "      resp = client.chat.completions.create(\n",
        "          model=model_name,\n",
        "          messages=[\n",
        "              {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "              {\"role\": \"user\", \"content\": text_prompt},\n",
        "          ],\n",
        "      )\n",
        "      content = resp.choices[0].message.content.strip()\n",
        "      match = re.search(r\"<answer>(.*?)</answer>\", content, re.DOTALL)\n",
        "      if not match:\n",
        "          return \"ERROR\"\n",
        "      raw = match.group(1)\n",
        "      # clean single-line and block comments, fix trailing commas\n",
        "      raw = re.sub(r\"//.*\", \"\", raw)\n",
        "      raw = re.sub(r\"/\\*.*?\\*/\", \"\", raw, flags=re.DOTALL)\n",
        "      raw = re.sub(r\",\\s*([}\\]])\", r\"\\1\", raw)\n",
        "      try:\n",
        "          result = ast.literal_eval(raw.strip())\n",
        "      except Exception:\n",
        "          return \"ERROR\"\n",
        "      return max(result, key=result.get) if mode == \"soft\" else result.get(\"Category\", \"ERROR\")\n",
        "\n",
        "\n",
        "    predictions = []\n",
        "    for start in tqdm(range(0, len(prompts), batch_size), desc=\"Processing Batches\"):\n",
        "        batch = prompts[start : start + batch_size]\n",
        "        with ThreadPoolExecutor(max_workers=batch_size) as executor:\n",
        "            predictions.extend(executor.map(_worker, batch))\n",
        "\n",
        "    accuracy = sum(p == t for p, t in zip(predictions, targets)) / len(targets)\n",
        "    print(f\"[{Path(model_name).name}][{mode}] Accuracy: {accuracy:.4f}\")\n",
        "    return accuracy\n"
      ],
      "metadata": {
        "id": "pD4868P5SmzV"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "models = [\"lgai/exaone-3-5-32b-instruct\"]\n",
        "for mode, model in product([\"hard\", \"soft\"], models):\n",
        "    acc = run_evaluation(model, mode)\n",
        "    results.append([mode, model, acc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZQuNVfgSu-J",
        "outputId": "a38f093c-4816-4916-a84c-a98a3392e952"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Batches: 100%|██████████| 32/32 [00:29<00:00,  1.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[exaone-3-5-32b-instruct][hard] Accuracy: 0.8320\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Batches: 100%|██████████| 32/32 [00:55<00:00,  1.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[exaone-3-5-32b-instruct][soft] Accuracy: 0.8480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(results, columns=[\"Mode\", \"Model\", \"Accuracy\"])\n",
        "print(df.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fY3oa2_eU8Wt",
        "outputId": "ef3af6d1-4fb6-4604-9316-68c7632d5262"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mode                        Model  Accuracy\n",
            "hard lgai/exaone-3-5-32b-instruct     0.832\n",
            "soft lgai/exaone-3-5-32b-instruct     0.848\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Выводы\n",
        "\n",
        "soft бьет hard (привет pirelli)\n",
        "\n",
        "1.\tГибкость формата\n",
        "- В soft-режиме мы используем все вероятности, которые модель приписывает каждой категории. Даже если правильная метка стоит не на первом месте, её «вес» учитывается при аргмаксе.\n",
        "\n",
        "2.\tСложности парсинга\n",
        "- В hard-режиме модель должна чётко придерживаться JSON-формата и вернуть именно поле \"Category\". Любая мелкая неточность или дополнительный текст (комментарий, лишняя запятая) приводит к сбою и ошибкам парсинга, что снижает надёжность."
      ],
      "metadata": {
        "id": "4jkEUqMOYQxD"
      }
    }
  ]
}