{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import pipeline\n",
        "from sklearn.metrics import accuracy_score, log_loss, classification_report\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ZxWdz7uOr4cT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/test.csv\"\n",
        "df = pd.read_csv(url, header=None, names=[\"label\",\"title\",\"description\"])"
      ],
      "metadata": {
        "id": "N_rCleiwr6s8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"text\"] = df[\"title\"] + \". \" + df[\"description\"]\n",
        "df = df.sample(n=500, random_state=42).reset_index(drop=True)\n",
        "\n",
        "texts = df[\"text\"].tolist()\n",
        "# в CSV метки от 1 до 4, переводим в 0–3\n",
        "y_true = df[\"label\"].values - 1\n",
        "\n",
        "# 2. Определяем имена классов\n",
        "candidate_labels = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]"
      ],
      "metadata": {
        "id": "FOdJD-H0u4gc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\n",
        "        \"zero-shot-classification\",\n",
        "        model=\"valhalla/distilbart-mnli-12-1\",  # компактная модель на NLI\n",
        "        device=-1  # CPU; для GPU укажите device=0\n",
        "    )\n",
        "candidate_labels = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqv6CqeZsAZ6",
        "outputId": "752fdb0d-5657-493c-c312-013a9f5cbde9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soft_preds = []   # накапливаем прогнозы вероятностей\n",
        "hard_preds = []   # накапливаем класс argmax\n",
        "for text in texts:\n",
        "    res = classifier(text, candidate_labels)\n",
        "    # преобразуем в вектор вероятностей в порядке candidate_labels\n",
        "    score_map = dict(zip(res[\"labels\"], res[\"scores\"]))\n",
        "    probs = [score_map[lbl] for lbl in candidate_labels]\n",
        "    soft_preds.append(probs)\n",
        "    hard_preds.append(res[\"labels\"][0])\n",
        "\n",
        "soft_preds = np.array(soft_preds)\n",
        "hard_pred_ids = np.array([candidate_labels.index(lbl) for lbl in hard_preds])\n"
      ],
      "metadata": {
        "id": "rf14ceZWsGQR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ll = log_loss(y_true, soft_preds, labels=list(range(len(candidate_labels))))\n",
        "acc = accuracy_score(y_true, hard_pred_ids)\n",
        "\n",
        "print(f\"Log Loss (soft predictions): {ll:.4f}\")\n",
        "print(f\"Accuracy  (hard predictions): {acc:.4f}\\n\")\n",
        "\n",
        "print(\"Classification report (hard predictions):\")\n",
        "print(classification_report(\n",
        "    y_true,\n",
        "    hard_pred_ids,\n",
        "    target_names=candidate_labels,\n",
        "    digits=4\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD7tU4wXsKLv",
        "outputId": "bd93dcc6-3132-411b-de51-dbaa6e6249cf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log Loss (soft predictions): 0.8414\n",
            "Accuracy  (hard predictions): 0.7240\n",
            "\n",
            "Classification report (hard predictions):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       World     0.6154    0.7934    0.6931       121\n",
            "      Sports     0.9333    0.9655    0.9492       116\n",
            "    Business     0.6188    0.7984    0.6972       124\n",
            "    Sci/Tech     0.8594    0.3957    0.5419       139\n",
            "\n",
            "    accuracy                         0.7240       500\n",
            "   macro avg     0.7567    0.7382    0.7203       500\n",
            "weighted avg     0.7578    0.7240    0.7115       500\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Log Loss (soft predictions): 0.8414\n",
        "\n",
        "  -\tЗначение ниже 1 говорит о том, что модель в целом выставляет умеренные вероятности: она не слишком «уверена» в каждом своём ответе, но и не даёт слишком размытые распределения.\n",
        "\n",
        "  -\tЕсть пространство для улучшения калибровки (например, с помощью temperature scaling или небольшого дообучения).\n",
        "\n",
        "Accuracy (hard predictions): 0.7240\n",
        "\n",
        "  - Модель верно угадала тему примерно в 72,4% случаев без какой-либо донастройки на конкретный датасет. Для zero-shot это вполне хороший результат.\n",
        "\n",
        "\n",
        "Итоги:\n",
        "\n",
        "Zero-shot без дообучения даёт приемлемый baseline (~72% точности), но остаётся значительный разрыв до supervised-классификаторов, которые на AG News обычно достигают >90%\n"
      ],
      "metadata": {
        "id": "YIvf4LJR1Ix6"
      }
    }
  ]
}
